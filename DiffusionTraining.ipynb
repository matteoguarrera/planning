{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Diffusion Model - No vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T17:08:36.457681Z",
     "start_time": "2023-04-23T17:08:35.785897Z"
    }
   },
   "outputs": [],
   "source": [
    "# from imports import * # just some imports\n",
    "from PushTDataset import *\n",
    "\n",
    "# Import synthetic dataset\n",
    "dataset_pushT = load_dataset_push_t() # same dataset as the paper\n",
    "\n",
    "dataset_ours, obs_dim, action_dim, name, fn_distance, fn_speed = load_dataset_lqr2d() # to clean,  @carlo\n",
    "# dataset_ours, obs_dim, action_dim, name, fn_distance, fn_speed  = load_dataset_lqr3d() # to clean, @carlo\n",
    "# dataset_ours, obs_dim, action_dim, name, fn_distance, fn_speed  = load_dataset_drone() # to clean,  @carlo\n",
    "# dataset_ours, obs_dim, action_dim, name, fn_distance, fn_speed  = load_dataset_lqr2d_observation() # to clean,  @carlo\n",
    "\n",
    "# Show distribution of trajectories length\n",
    "show_statistics(dataset_paper=dataset_pushT,\n",
    "                dataset_ours=dataset_ours)\n",
    "\n",
    "# create dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset_ours,\n",
    "    batch_size=256,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    "    # accelerate cpu-gpu transfer\n",
    "    pin_memory=True,\n",
    "    # don't kill worker process after each epoch\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# visualize data in batch\n",
    "batch = next(iter(dataloader))\n",
    "print(\"batch['obs'].shape:\", batch['obs'].shape)\n",
    "print(\"batch['action'].shape\", batch['action'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:22:20.724747Z",
     "start_time": "2023-04-23T15:22:20.682335Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_pushT.stats['action'], dataset_pushT.stats['obs']\n",
    "dataset_ours.stats['action'], dataset_ours.stats['obs']\n",
    "# dataset_ours[0], dataset_pushT[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Learning Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T17:09:03.823150Z",
     "start_time": "2023-04-23T17:09:03.737816Z"
    }
   },
   "outputs": [],
   "source": [
    "#@markdown ### **Network Demo**\n",
    "# from draw import DrawOptions\n",
    "from Components import *\n",
    "\n",
    "# for 2d dataset 8 is ok for 3d 4\n",
    "SHRINK = 8 # how much small the network wrt papers\n",
    "\n",
    "\n",
    "TYPE = torch.float32\n",
    "down_dims = [256//SHRINK, 512//SHRINK, 1024//SHRINK]\n",
    "print('Dimension of the hidden layers: ', down_dims)\n",
    "\n",
    "# create network object\n",
    "noise_pred_net = ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon,\n",
    "    down_dims = down_dims,\n",
    "    kernel_size=5,\n",
    "    n_groups=4\n",
    ")\n",
    "\n",
    "# example inputs\n",
    "noised_action = torch.randn((1, pred_horizon, action_dim),dtype=TYPE)\n",
    "obs = torch.zeros((1, obs_horizon, obs_dim), dtype=TYPE)\n",
    "diffusion_iter = torch.zeros((1,), dtype=TYPE)\n",
    "\n",
    "# the noise prediction network\n",
    "# takes noisy action, diffusion iteration and observation as input\n",
    "# predicts the noise added to action\n",
    "noise = noise_pred_net(\n",
    "    sample=noised_action,\n",
    "    timestep=diffusion_iter,\n",
    "    global_cond=obs.flatten(start_dim=1))\n",
    "\n",
    "# illustration of removing noise\n",
    "# the actual noise removal is performed by NoiseScheduler\n",
    "# and is dependent on the diffusion noise schedule\n",
    "denoised_action = noised_action - noise\n",
    "\n",
    "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
    "num_diffusion_iters = 100\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_diffusion_iters,\n",
    "    # the choise of beta schedule has big impact on performance\n",
    "    # we found squared cosine works the best\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    # clip output to [-1,1] to improve stability\n",
    "    clip_sample=True,\n",
    "    # our network predicts noise (instead of denoised action)\n",
    "    prediction_type='epsilon'\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "_ = noise_pred_net.to(device)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "# Exponential Moving Average\n",
    "# accelerates training and improves stability\n",
    "# holds a copy of the model weights\n",
    "ema = EMAModel(\n",
    "    model=noise_pred_net,\n",
    "    power=0.75)\n",
    "\n",
    "# Standard ADAM optimizer\n",
    "# Note that EMA parametesr are not optimized\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=noise_pred_net.parameters(),\n",
    "    lr=9e-5, weight_decay=3e-5)\n",
    "\n",
    "# Cosine LR schedule with linear warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=len(dataloader) * num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda env config vars set PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "# !conda env config vars list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:55:56.875580Z",
     "start_time": "2023-04-23T14:38:22.931584Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "now = datetime.now()  # current date and time\n",
    "date_time = now.strftime(\"%m_%d_%H_%M_%S\")\n",
    "\n",
    "folder = f'pretrained/{name}_shr{SHRINK}_{date_time}'\n",
    "if not os.path.isfile(folder):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    # os.mkdir(folder)\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "writer = SummaryWriter(log_dir=folder) # log tensorboard\n",
    "\n",
    "LOSS = []\n",
    "with tqdm(range(num_epochs), desc='Epoch', leave=False) as tglobal:\n",
    "    # epoch loop\n",
    "    for epoch_idx in tglobal:\n",
    "        epoch_loss = list()\n",
    "        if epoch_idx%20 == 0:\n",
    "            torch.save(ema.averaged_model.state_dict(), f'./{folder}/model_{name}_ema_{epoch_idx}_{num_epochs}_shr{SHRINK}.ckpt')\n",
    "\n",
    "        # batch loop\n",
    "        with tqdm(dataloader, desc='Batch', leave=False) as tepoch:\n",
    "            for nbatch in tepoch:\n",
    "                # data normalized in dataset\n",
    "                # device transfer\n",
    "                nobs = nbatch['obs'].to(TYPE).to(device)\n",
    "                naction = nbatch['action'].to(TYPE).to(device)\n",
    "                B = nobs.shape[0]\n",
    "\n",
    "                # observation as FiLM conditioning\n",
    "                # (B, obs_horizon, obs_dim)\n",
    "                obs_cond = nobs[:,:obs_horizon,:]\n",
    "                # (B, obs_horizon * obs_dim)\n",
    "                obs_cond = obs_cond.flatten(start_dim=1).float()\n",
    "\n",
    "                # sample noise to add to actions\n",
    "                noise = torch.randn(naction.shape, device=device) # can be done a priori before starting\n",
    "\n",
    "                # sample a diffusion iteration for each data point\n",
    "                timesteps = torch.randint(\n",
    "                    0, noise_scheduler.config.num_train_timesteps,\n",
    "                    (B,), device=device\n",
    "                ).long()\n",
    "\n",
    "                # add noise to the clean images according to the noise magnitude at each diffusion iteration\n",
    "                # (this is the forward diffusion process)\n",
    "                noisy_actions = noise_scheduler.add_noise(\n",
    "                    naction, noise, timesteps).float()\n",
    "\n",
    "                # predict the noise residual\n",
    "                noise_pred = noise_pred_net(\n",
    "                    noisy_actions, timesteps, global_cond=obs_cond)\n",
    "\n",
    "                # L2 loss\n",
    "                loss = nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "                # optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                # step lr scheduler every batch\n",
    "                # this is different from standard pytorch behavior\n",
    "                lr_scheduler.step()\n",
    "\n",
    "                # update Exponential Moving Average of the model weights\n",
    "                ema.step(noise_pred_net)\n",
    "\n",
    "                # logging\n",
    "                loss_cpu = loss.item()\n",
    "                epoch_loss.append(loss_cpu)\n",
    "                tepoch.set_postfix(loss=loss_cpu)\n",
    "\n",
    "                if loss_cpu < 0.02 or np.isnan(loss_cpu):\n",
    "                    done = True\n",
    "                    break\n",
    "\n",
    "        writer.add_scalar('Training/loss_avg', np.mean(epoch_loss), epoch_idx)\n",
    "        writer.add_scalar('Training/loss_std', np.std(epoch_loss), epoch_idx)\n",
    "\n",
    "        LOSS.append(epoch_loss)\n",
    "        tglobal.set_postfix(loss=np.mean(epoch_loss))\n",
    "\n",
    "torch.save(noise_pred_net.state_dict(), f'./{folder}/model_{name}_{epoch_idx}_{num_epochs}_shr{SHRINK}.ckpt')\n",
    "torch.save(ema.averaged_model.state_dict(), f'./{folder}/model_{name}_ema_{epoch_idx}_{num_epochs}_shr{SHRINK}.ckpt')\n",
    "\n",
    "# Weights of the EMA model\n",
    "# is used for inference\n",
    "ema_noise_pred_net = ema.averaged_model        # 0.000204,    # 0.000517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:32:05.539944Z",
     "start_time": "2023-04-23T13:32:05.471161Z"
    }
   },
   "outputs": [],
   "source": [
    "LOSS\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for l in LOSS[:]:\n",
    "    ax.plot(l)\n",
    "plt.show()\n",
    "\n",
    "with open(f'{folder}/LOSS_model_{name}_ema_{epoch_idx}_{num_epochs}_shr{SHRINK}.pickle', 'wb') as handle:\n",
    "    pickle.dump(LOSS, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusionProj",
   "language": "python",
   "name": "diffusionproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
